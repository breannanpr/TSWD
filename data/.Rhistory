library(writexl)
library(ggplot2)
library(readxl)
library(writexl)
# read and install cardata into workable dataframe.
cardat = "carbitrage.xlsx"
cardatwb = read_excel(cardat)
## specify new file path
newcardat = "newcarbitrage.xlsx"
write_xlsx(cardat, newcardat)
## specify new file path
newcardat = "newcarbitrage.xlsx"
write_xlsx(cardat, newcardat)
write_xlsx(carbitrage, newcardat)
View(cardatwb)
install.packages("dplyr")
library(dplyr)
carcounts = cardatwb %>%
group_by(make, model) %>%
summarize(count = n()) %>%
arrange(desc(count))
#create visualization 1: A visualization that illustrates what makes and models of cars are most popular, using ggplot
ggplot(carcounts, aes(x = reorder(paste(make, model), -count), y = count)) +
geom_bar(stat = "identity", fill = "skyblue") +
coord_flip() +
labs(
tile = "Most Popular Car Makes and Models",
x = "Make and Model",
y = "Count"
) +
theme_minimal() +
theme(
axis.text.y = element_text(size = 8),
plot.title = element_text(hjust = 0.5)
)
#install tidyverse and ggplot within tidy verse
install.packages("tidyverse")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
library(readxl)
library(writexl)
library(dplyr)
# read and install cardata into workable dataframe.
cardat = "carbitrage.xlsx"
cardatwb = read_excel(cardat)
# prep data, count frequency for each make and model.
carcounts = cardatwb %>%
group_by(make, model) %>%
summarize(count = n()) %>%
arrange(desc(count))
#create visualization 1: A visualization that illustrates what makes and models of cars are most popular, using ggplot
ggplot(carcounts, aes(x = reorder(paste(make, model), -count), y = count)) +
geom_bar(stat = "identity", fill = "skyblue") +
coord_flip() +
labs(
tile = "Most Popular Car Makes and Models",
x = "Make and Model",
y = "Count"
) +
theme_minimal() +
theme(
axis.text.y = element_text(size = 8),
plot.title = element_text(hjust = 0.5)
)
category = gsub("", "", category)
# clean data, normalize and unify categories
normcarcounts = function(category){
category = to lower(category)
# prep data, count frequency for each make and model.
cardatwb = cardatwb %>%
mutate(make = normcarcounts(make),
model = normcarcounts(model))
# clean data, normalize and unify categories
normcarcounts = function(category){
category = to lower(category)
# prep data, count frequency for each make and model.
cardatwb = cardatwb %>%
mutate(make = normcarcounts(make),
model = normcarcounts(model))
# read and install cardata into workable dataframe.
cardat = "carbitrage.xlsx"
cardatwb = read_excel(cardat)
# clean data, normalize and unify categories
normcarcounts = function(category){
category = to lower(category)
category = tolower(category)
# clean data, normalize and unify categories
normcarcounts = function(category){
category = tolower(category)
category = gsub("", "", category)
rules <- list(
c("chevrolet", "chevy"),
c("ford"),
c("toyota"),
c("honda"),
c("nissan"),
c("hyundai"),
c("kia"),
c("volkswagen", "vw"),
c("bmw"),
c("mercedes-benz", "mercedes"),
c("audi"),
c("subaru"),
c("jeep"),
c("mazda"),
c("lexus"),
c("gmc"),
c("cadillac"),
c("acura"),
c("buick"),
c("chrysler"),
c("dodge"),
c("jaguar"),
c("volvo"),
c("lincoln"),
c("porsche"),
c("landrover", "land-rover", "land rover"),
c("tesla")
)
for (rule in rules) {
if category %in% rule) {
# clean data, normalize and unify categories
normcarcounts = function(category){
category = tolower(category)
category = gsub("", "", category)
rules <- list(
c("chevrolet", "chevy"),
c("ford"),
c("toyota"),
c("honda"),
c("nissan"),
c("hyundai"),
c("kia"),
c("volkswagen", "vw"),
c("bmw"),
c("mercedes-benz", "mercedes"),
c("audi"),
c("subaru"),
c("jeep"),
c("mazda"),
c("lexus"),
c("gmc"),
c("cadillac"),
c("acura"),
c("buick"),
c("chrysler"),
c("dodge"),
c("jaguar"),
c("volvo"),
c("lincoln"),
c("porsche"),
c("landrover", "land-rover", "land rover"),
c("tesla")
)
for (rule in rules) {
if (category %in% rule) {
return(rule[1])
}
}
return(category)
}
# prep data, count frequency for each make and model.
cardatwb = cardatwb %>%
mutate(make = normcarcounts(make),
model = normcarcounts(model))
carcounts = cardatwb %>%
group_by(make, model) %>%
summarize(count = n()) %>%
arrange(desc(count))
#create visualization 1: A visualization that illustrates what makes and models of cars are most popular, using ggplot
ggplot(carcounts, aes(x = reorder(paste(make, model), -count), y = count)) +
geom_bar(stat = "identity", fill = "skyblue") +
coord_flip() +
labs(
tile = "Most Popular Car Makes and Models",
x = "Make and Model",
y = "Count"
) +
theme_minimal() +
theme(
axis.text.y = element_text(size = 8),
plot.title = element_text(hjust = 0.5)
)
return(simgroups)
vocabstrings = function(input_vector, threshold = 0.2){
simgroups = list()
for (string in input_vector) {
matchedgroup = NULL
for (group in simgroups) {
if (any(stringdist::stringdistmatrix(string, group) = threshold)) {
vocabstrings = function(input_vector, threshold = 0.2){
simgroups = list()
for (string in input_vector) {
matchedgroup = NULL
for (group in simgroups) {
if (any(stringdist::stringdistmatrix(string, group) <= threshold)) {
matchedgroup = group
break
}
}
if (is.null(matchedgroup)) {
simgroups[[lenght(simgroups) + 1]] = string
} else {
matchedgroup[[lenght(matchedgroup) + 1]] = string
}
}
return(simgroups)
}
normcarcounts = function(category){
category = tolower(category)
category = gsub("", "", category)
rules <- list(
c("chevrolet", "chevy"),
c("ford"),
c("toyota"),
c("honda"),
c("nissan"),
c("hyundai"),
c("kia"),
c("volkswagen", "vw"),
c("bmw"),
c("mercedes-benz", "mercedes"),
c("audi"),
c("subaru"),
c("jeep"),
c("mazda"),
c("lexus"),
c("gmc"),
c("cadillac"),
c("acura"),
c("buick"),
c("chrysler"),
c("dodge"),
c("jaguar"),
c("volvo"),
c("lincoln"),
c("porsche"),
c("landrover", "land-rover", "land rover"),
c("tesla")
)
for (rule in rules) {
if (category %in% rule) {
return(rule[1])
}
}
return(category)
}
vocabstrings = function(input_vector, threshold = 0.2){
simgroups = list()
for (string in input_vector) {
matchedgroup = NULL
for (group in simgroups) {
if (any(stringdist::stringdistmatrix(string, group) <= threshold)) {
matchedgroup = group
break
}
}
if (is.null(matchedgroup)) {
simgroups[[lenght(simgroups) + 1]] = string
} else {
matchedgroup[[lenght(matchedgroup) + 1]] = string
}
}
return(simgroups)
}
# prep data, count frequency for each make and model.
cardatwb = cardatwb %>%
mutate(make = normcarcounts(make),
model = normcarcounts(model))
carcounts = cardatwb %>%
group_by(make, model) %>%
summarize(count = n()) %>%
arrange(desc(count))
#create visualization 1: A visualization that illustrates what makes and models of cars are most popular, using ggplot
ggplot(carcounts, aes(x = reorder(paste(make, model), -count), y = count)) +
geom_bar(stat = "identity", fill = "skyblue") +
coord_flip() +
labs(
tile = "Most Popular Car Makes and Models",
x = "Make and Model",
y = "Count"
) +
theme_minimal() +
theme(
axis.text.y = element_text(size = 8),
plot.title = element_text(hjust = 0.5)
)
similar_make_groups <- find_similar_strings(cardatwb$make)
similar_model_groups <- find_similar_strings(cardatwb$model)
simmodelgroups = find_similar_strings(cardatwb$model)
simmakegroups = find_similar_strings(cardatwb$make)
install.packages("stringdist")
library(stringdist)
# read and install cardata into workable dataframe.
cardat = "carbitrage.xlsx"
cardatwb = read_excel(cardat)
# clean data, normalize and unify categories, and adjust for misspellings.
normcarcounts = function(category){
category = tolower(category)
category = gsub("", "", category)
rules <- list(
c("chevrolet", "chevy"),
c("ford"),
c("toyota"),
c("honda"),
c("nissan"),
c("hyundai"),
c("kia"),
c("volkswagen", "vw"),
c("bmw"),
c("mercedes-benz", "mercedes"),
c("audi"),
c("subaru"),
c("jeep"),
c("mazda"),
c("lexus"),
c("gmc"),
c("cadillac"),
c("acura"),
c("buick"),
c("chrysler"),
c("dodge"),
c("jaguar"),
c("volvo"),
c("lincoln"),
c("porsche"),
c("landrover", "land-rover", "land rover"),
c("tesla")
)
for (rule in rules) {
if (category %in% rule) {
return(rule[1])
}
}
return(category)
}
vocabstrings = function(input_vector, threshold = 0.2){
simgroups = list()
for (string in input_vector) {
matchedgroup = NULL
for (group in simgroups) {
if (any(stringdist::stringdistmatrix(string, group) <= threshold)) {
matchedgroup = group
break
}
}
if (is.null(matchedgroup)) {
simgroups[[lenght(simgroups) + 1]] = string
} else {
matchedgroup[[lenght(matchedgroup) + 1]] = string
}
}
return(simgroups)
}
# prep data, count frequency for each make and model.
cardatwb = cardatwb %>%
mutate(make = normcarcounts(make),
model = normcarcounts(model))
simmodelgroups = find_similar_strings(cardatwb$model)
simmakegroups = vocabstrings(cardatwb$make)
simmodelgroups = vocabstrings(cardatwb$model)
# read and install cardata into workable dataframe.
cardat = "carbitrage.xlsx"
cardatwb = read_excel(cardat)
# clean data, normalize and unify categories, and adjust for misspellings.
normcarcounts = function(category){
category = tolower(category)
category = gsub("", "", category)
rules <- list(
c("chevrolet", "chevy"),
c("ford"),
c("toyota"),
c("honda"),
c("nissan"),
c("hyundai"),
c("kia"),
c("volkswagen", "vw"),
c("bmw"),
c("mercedes-benz", "mercedes"),
c("audi"),
c("subaru"),
c("jeep"),
c("mazda"),
c("lexus"),
c("gmc"),
c("cadillac"),
c("acura"),
c("buick"),
c("chrysler"),
c("dodge"),
c("jaguar"),
c("volvo"),
c("lincoln"),
c("porsche"),
c("landrover", "land-rover", "land rover"),
c("tesla")
)
for (rule in rules) {
if (category %in% rule) {
return(rule[1])
}
}
return(category)
}
vocabstrings = function(input_vector, threshold = 0.2){
simgroups = list()
for (string in input_vector) {
matchedgroup = NULL
for (group in simgroups) {
if (any(stringdist::stringdistmatrix(string, group) <= threshold)) {
matchedgroup = group
break
}
}
if (is.null(matchedgroup)) {
simgroups[[length(simgroups) + 1]] = string
} else {
matchedgroup[[length(matchedgroup) + 1]] = string
}
}
return(simgroups)
}
# prep data, count frequency for each make and model.
cardatwb = cardatwb %>%
mutate(make = normcarcounts(make),
model = normcarcounts(model))
normcarcounts = function(category){
category = tolower(category)
category = gsub(" ", "", category)
return(category)
}
vocabstrings = function(input_vector, threshold = 0.2){
simgroups = list()
for (string in input_vector) {
matchedgroup = NULL
for (group in simgroups) {
if (any(stringdist::stringdistmatrix(string, group) <= threshold)) {
matchedgroup = group
break
}
}
if (is.null(matchedgroup)) {
simgroups[[length(simgroups) + 1]] = string
} else {
matchedgroup[[length(matchedgroup) + 1]] = string
}
}
return(simgroups)
}
normcarcounts = function(category){
category = tolower(category)
category = gsub(" ", "", category)
return(category)
}
# prep data, count frequency for each make and model.
cardatwb = cardatwb %>%
mutate(
make = normcarcounts(make),
model = normcarcounts(model)
)
simmakegroups = vocabstrings(cardatwb$make)
# convert to lowercase, remove spaces
normcarcounts = function(category){
category = tolower(category)
category = gsub(" ", "", category)
return(category)
}
library(ggplot2)
library(readxl)
library(writexl)
library(dplyr)
library(stringdist)
# read and install cardata into workable dataframe.
cardat = "carbitrage.xlsx"
cardatwb = read_excel(cardat)
# convert to lowercase, remove spaces
normcarcounts = function(category){
category = tolower(category)
category = gsub(" ", "", category)
return(category)
}
# normalize make and model columns
cardatwb = cardatwb %>%
mutate(
make = normcarcounts(make),
model = normcarcounts(model)
)
# find similar makes and models
simmakegroups = stringdist::stringdistmatrix(cardatwb$make, cardatwb$make) <= 2
simmodelgroups = stringsdist::stringdistmatrix(cardatwb$model, cardatwb$model) <= 2
simmodelgroups = stringdist::stringdistmatrix(cardatwb$model, cardatwb$model) <= 2
# find similar makes and models
simmakegroups = stringdist::stringdistmatrix(cardatwb$make, cardatwb$make) <= 1
simmodelgroups = stringdist::stringdistmatrix(cardatwb$model, cardatwb$model) <= 1
install.packages("fuzzyjoin")
library(fuzzyjoin)
# find similar makes and models
makesim = stringdist_left_join(cardatwb, cardatwb, by = c("make" = "make"), method = "lv", max_dist = 2)
install.packages("cli")
# find similar makes and models
makesim = stringdist_left_join(cardatwb, cardatwb, by = c("make" = "make"), method = "lv", max_dist = 2)
library(ggplot2)
library(readxl)
library(writexl)
library(dplyr)
library(fuzzyjoin)
source("~/GitHub/TSWD/TSWD_Data_Viz_092523.R", echo=TRUE)
install.packages("fuzzyjoin")
install.packages("dplyr")
